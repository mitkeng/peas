{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Y8c60n2lr9Gv",
        "WA2QWYcTkagJ",
        "CXItAsnGPxOC",
        "gvlwYWRR2PXK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**PEÃ…S** for **P**recision **E**nsemble **A**utonomous **S**ampling\n",
        "\n",
        "#### Documentation: https://github.com/mitkeng/peas\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "## **Functionalities:**\n",
        "\n",
        "*   ### Rank charge sites\n",
        "*   ### Predict equilibrium charge state\n",
        "*   ### Soft geometry optimization\n",
        "*   ### Compute model relative energy score\n",
        "*   ### Generate [M+H]$^+$ or `` `` [M-H]$^-$ ensemble\n",
        "*   ### Conformer similarity filtering\n",
        "\n",
        "\n",
        "<br/>\n"
      ],
      "metadata": {
        "id": "1hr_BmNk9qgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Packages Installation**"
      ],
      "metadata": {
        "id": "Y8c60n2lr9Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n",
        "!pip install tensorflow_decision_forests -U -qq\n",
        "!pip install trainer\n",
        "!pip install ase\n",
        "!pip install py3Dmol\n",
        "!pip install openbabel-wheel\n",
        "\n",
        "!pip install --upgrade mlatom\n",
        "!pip install torchani\n",
        "!pip install pymol\n",
        "\n",
        "!pip install chemml\n",
        "!pip install e3nn\n",
        "from chemml.chem import Molecule\n",
        "from chemml.datasets import load_organic_density"
      ],
      "metadata": {
        "id": "J7P5nCv2Ofq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%capture\n",
        "try:\n",
        "  !wget https://raw.githubusercontent.com/rdkit/rdkit/master/Docs/Book/data/cdk2.sdf\n",
        "  !wget https://raw.githubusercontent.com/mitkeng/SEER/refs/heads/main/data/seer_neg.csv\n",
        "  !wget https://raw.githubusercontent.com/mitkeng/SEER/refs/heads/main/data/seer_pos.csv\n",
        "  !wget https://github.com/mitkeng/CCS_Focusing/raw/main/models/ML_ccs.keras\n",
        "  !wget https://raw.githubusercontent.com/mitkeng/CCS_Focusing/refs/heads/main/error.csv\n",
        "  !wget https://raw.githubusercontent.com/mitkeng/SEER/refs/heads/main/data/neg_chargedatasetX2.csv\n",
        "  !wget https://raw.githubusercontent.com/mitkeng/SEER/refs/heads/main/data/pos_chargedatasetX2.csv\n",
        "  !wget https://github.com/mitkeng/SEER/raw/refs/heads/main/models/seer_neg_model.zip\n",
        "  !wget https://github.com/mitkeng/SEER/raw/refs/heads/main/models/seer_pos_model.zip\n",
        "\n",
        "  !pip install ydf -U -qq\n",
        "  import ydf\n",
        "  !which pymol\n",
        "except:\n",
        "  pass\n",
        "\n",
        "!pip install ydf -U -qq\n",
        "import ydf\n",
        "!which pymol\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge python=3.12\n",
        "!mamba install -c schrodinger pymol-bundle --yes\n",
        "\n",
        "\n",
        "!pip install --upgrade setuptools"
      ],
      "metadata": {
        "id": "ilK4beZADour"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#@markdown ### Install Dependencies\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import py3Dmol\n",
        "from tensorflow import keras\n",
        "from numpy.core.arrayprint import printoptions\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "try:\n",
        "  np.set_printoptions(precision=3, suppress=True)\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  import pymol\n",
        "except:\n",
        "  pass\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "k6pWr0n1r9Gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **User's Seed Structure and Charge Selection**"
      ],
      "metadata": {
        "id": "sQhYV3rCUFXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "#@markdown ###Enter a molecule name and smile. Leave the **smile** field blank if a user XYZ file is provided in current directory. Select an ion charge mode.\n",
        "#@markdown <br/>\n",
        "molecule_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter name\"}\n",
        "molecule_name = molecule_name.replace(\" \",\"\")\n",
        "smile = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter smile\"}\n",
        "folder_name = molecule_name+\"_folder\"\n",
        "file_name = folder_name\n",
        "charge_mode = \"[M+H]+\" # @param [\"[M+H]+\",\"[M-H]-\"]\n",
        "\n",
        "import rdkit\n",
        "import chemml\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "try:\n",
        "  np.set_printoptions(precision=3, suppress=True)\n",
        "except:\n",
        "  pass\n",
        "from chemml.chem import Molecule\n",
        "import pandas as pd\n",
        "import py3Dmol\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from chemml.chem import Molecule\n",
        "from chemml.datasets import load_organic_density\n",
        "from openbabel import pybel\n",
        "import os\n",
        "import pymol\n",
        "import ydf\n",
        "import os\n",
        "import ase\n",
        "from numpy.core.arrayprint import printoptions\n",
        "import pymol\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ase import io\n",
        "from ase.io import read, write\n",
        "import os\n",
        "import shutil\n",
        "import __main__\n",
        "__main__.pymol_argv = ['pymol','-qc']\n",
        "import pymol\n",
        "from pymol import cmd, stored\n",
        "from google.colab import output\n",
        "pymol.finish_launching()\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from timeit import default_timer as timer\n",
        "import time\n",
        "import pytz\n",
        "import glob\n",
        "import zipfile\n",
        "\n",
        "\n",
        "mol_file = \"{}.xyz\".format(molecule_name)\n",
        "\n",
        "mol = pybel.readstring(\"smi\", smile)\n",
        "mol.addh()\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  mol.make3D(forcefield='MMFF94')\n",
        "  mol.localopt(forcefield='GAFF', steps=1000)\n",
        "if charge_mode == \"[M-H]-\" and \"P\" in smile.upper():\n",
        "  step = int(len(mol.atoms)*1000)\n",
        "  mol.make3D(forcefield='MMFF94', steps=step)\n",
        "  mol.localopt(forcefield='MMFF94', steps=step)\n",
        "if charge_mode == \"[M-H]-\" and \"P\" not in smile.upper():\n",
        "  step = int(len(mol.atoms)*1000)\n",
        "  mol.make3D(forcefield='GAFF', steps=step)\n",
        "  mol.localopt(forcefield='GAFF', steps=step)\n",
        "\n",
        "try:\n",
        "  mol.write(\"xyz\", mol_file)\n",
        "except:\n",
        "  print(\"File of molecule already exist\")\n",
        "  pass\n",
        "\n",
        "chk_file = open(mol_file)\n",
        "corr_file = open(\"{}_.xyz\".format(molecule_name),\"w\")\n",
        "for c in chk_file:\n",
        "  try:\n",
        "    if c.split()[0]!=\"\":\n",
        "      print(c.strip(),file=corr_file)\n",
        "  except:\n",
        "    print(molecule_name, file=corr_file)\n",
        "corr_file.close()\n",
        "\n",
        "try:\n",
        "    os.remove(mol_file)\n",
        "    os.rename(\"{}_.xyz\".format(molecule_name),\"{}.xyz\".format(molecule_name))\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "try:\n",
        "  with zipfile.ZipFile('seer_pos_model.zip', 'r') as zip_:\n",
        "    zip_.extractall('seer_pos_model')\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  with zipfile.ZipFile('seer_neg_model.zip', 'r') as zip_:\n",
        "    zip_.extractall('seer_neg_model')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  model5 = ydf.load_model(\"seer_pos_model\")\n",
        "  train_file = \"pos_chargedatasetX2.csv\"\n",
        "if charge_mode == \"[M-H]-\":\n",
        "  model5 = ydf.load_model(\"seer_neg_model\")\n",
        "  train_file = \"neg_chargedatasetX2.csv\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  os.makedirs(folder_name)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  shutil.move(\"predict/{}\".format(data_files[0]),\n",
        "              \"run_hist/{}\".format(folder_name,rename_ ))\n",
        "except:\n",
        "  pass\n",
        "\n",
        "shutil.rmtree\n",
        "try:\n",
        "  shutil.rmtree(\"test_data\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(\"predict\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  if molecule_name+\".xyz\" in os.listdir(\"/content/\"):\n",
        "    shutil.move(molecule_name+\".xyz\", folder_name)\n",
        "  else:\n",
        "    if glob.glob(\"*.xyz\")[0] in (os.listdir(\"/content/\")):\n",
        "      shutil.move(glob.glob(\"*.xyz\")[0], folder_name)\n",
        "except:\n",
        "  try:\n",
        "    if glob.glob(\"*.xyz\")[0] in (os.listdir(\"/content/\")):\n",
        "        shutil.move(glob.glob(\"*.xyz\")[0], folder_name)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "start = timer()\n",
        "time_initiated = datetime.now(pytz.timezone('America/Los_Angeles')).strftime(\"%H:%M:%S     %d-%b-%Y\")\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RnMPpRDGo4HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Execute Charge Model Assignment**"
      ],
      "metadata": {
        "id": "WA2QWYcTkagJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Construct ML data\n",
        "import re\n",
        "import math\n",
        "import csv\n",
        "import os\n",
        "start = timer()\n",
        "time_initiated = datetime.now(pytz.timezone('America/Los_Angeles')).strftime(\"%H:%M:%S     %d-%b-%Y\")\n",
        "\n",
        "\n",
        "\n",
        "Name = file_name\n",
        "d = len(os.listdir(\"{}/\".format(Name)))\n",
        "id = os.listdir(\"{}/\".format(Name))\n",
        "\n",
        "\n",
        "COM_list,mass_list,conf_num,surface_area= ([],[],\n",
        "                                           [],[])\n",
        "\n",
        "for i in range(d):\n",
        "  try:\n",
        "    if id[i][-3:].lower()!=\"csv\":\n",
        "\n",
        "      cartesian_file= \"{}/{}\".format(Name,id[i])\n",
        "      mol = ase.io.read(cartesian_file)\n",
        "\n",
        "      COM = mol.get_center_of_mass(scaled=False)\n",
        "      COM_list.append(COM)\n",
        "\n",
        "      mol_mass = mol.get_masses()\n",
        "      mass_list.append(sum(mol_mass))\n",
        "      cmd.load(\"{}/{}\".format(Name, id[i]))\n",
        "      cmd.set('dot_solvent', 0)\n",
        "      cmd.set('dot_density',2)\n",
        "      new_id=re.sub(\"[^0-9]\", \"\", id[i])\n",
        "      conf_num.append(new_id)\n",
        "\n",
        "      sa=cmd.get_area('all')\n",
        "      total_atom=cmd.count_atoms()\n",
        "      surface_area.append(sa)\n",
        "\n",
        "  except OSError:\n",
        "    pass\n",
        "  cmd.reinitialize()\n",
        "\n",
        "COM_List=[]\n",
        "for co in COM_list:\n",
        "  COM_List.append((co[0],co[1],co[2]))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZsaQG8xGO5db",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Data Prepration\n",
        "\n",
        "import statistics\n",
        "from statistics import mode\n",
        "Name=file_name\n",
        "id3 = os.listdir(\"{}/\".format(Name))\n",
        "id2 = [i for i in id3 if i != '.ipynb_checkpoints']\n",
        "\n",
        "\n",
        "def EN_moments(a):\n",
        "  M_x=0\n",
        "  M_y=0\n",
        "  M_z=0\n",
        "  total_EN=0\n",
        "  for i in range(len(a)):\n",
        "    M_x +=float(atomic_EN[xyz_list[i][0]])*float(xyz_list[i][1])\n",
        "    M_y +=float(atomic_EN[xyz_list[i][0]])*float(xyz_list[i][2])\n",
        "    M_z +=float(atomic_EN[xyz_list[i][0]])*float(xyz_list[i][3])\n",
        "    total_EN += atomic_EN[xyz_list[i][0]]\n",
        "  return M_x, M_y, M_z, total_EN\n",
        "\n",
        "def center_of_EN(M_x, M_y, M_z, total_EN):\n",
        "  EN_COM=[]\n",
        "  for i in range(len(xyz_list)):\n",
        "    X_EN = M_x/total_EN\n",
        "    Y_EN = M_y/total_EN\n",
        "    Z_EN = M_z/total_EN\n",
        "  return X_EN,Y_EN,Z_EN\n",
        "\n",
        "\n",
        "molecule_dict,proton_coord,dub_list,H_distance=([],[],\n",
        "                                                [],[])\n",
        "\n",
        "fi_name,conf_nu,conf_list,bond_count=([],[],\n",
        "                                      [],[])\n",
        "\n",
        "for I in id2:\n",
        "\n",
        "  if I[-3:].lower()==\"xyz\":\n",
        "    try:\n",
        "      confn= I.split(\".\")[0]\n",
        "      coord = open(\"{}/{}\".format(Name,I))\n",
        "      conf_list.append(I)\n",
        "      at_coord = []\n",
        "      for line in coord:\n",
        "          line = line.split()\n",
        "\n",
        "          if len(line) > 2:\n",
        "              at_coord.append(line)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    candidate_O_lis,charge_site,index_min =([],[],[])\n",
        "    index_min2,bond_count,bond_count_O=([],[],[])\n",
        "\n",
        "    for i in range(len(at_coord)):\n",
        "      hetero_list=[]\n",
        "      index_carb=[]\n",
        "      count_O=0\n",
        "      if at_coord[i][0] == \"O\" :\n",
        "        for i2 in range(len(at_coord)):\n",
        "          C=0\n",
        "          H=0\n",
        "          C2=0\n",
        "          if at_coord[i2][0] !=\"O\":\n",
        "            try:\n",
        "              x = float(at_coord[i][1]) - float(at_coord[i2][1])\n",
        "              y = float(at_coord[i][2]) - float(at_coord[i2][2])\n",
        "              z = float(at_coord[i][3]) - float(at_coord[i2][3])\n",
        "              distance = (x**2 + y**2 + z**2)**0.5\n",
        "            except:\n",
        "              pass\n",
        "            if distance <1.2 and count_O==0 and charge_mode ==\"[M-H]-\":\n",
        "              count_O+=1\n",
        "              index_carb.append((i,distance))\n",
        "              index_min.append((distance,at_coord[i]))\n",
        "            if distance <1.6 and count_O==0 and charge_mode ==\"[M+H]+\":\n",
        "              count_O+=1\n",
        "              index_carb.append((i,distance))\n",
        "              index_min.append((distance,at_coord[i]))\n",
        "\n",
        "        hetero_list.append(at_coord[i2])\n",
        "\n",
        "      count_N=0\n",
        "\n",
        "      if at_coord[i][0] == \"N\" :\n",
        "        conf_nu.append(I)\n",
        "        hetero_list.append(at_coord[i])\n",
        "        for i3 in range(len(at_coord)):\n",
        "          if at_coord[i3][0] != \"N\" :\n",
        "            try:\n",
        "              x = float(at_coord[i][1]) - float(at_coord[i3][1])\n",
        "              y = float(at_coord[i][2]) - float(at_coord[i3][2])\n",
        "              z = float(at_coord[i][3]) - float(at_coord[i3][3])\n",
        "              distance2 = (x**2 + y**2 + z**2)**0.5\n",
        "            except:\n",
        "              pass\n",
        "            if distance2 <1.2 and count_N==0 and charge_mode ==\"[M-H]-\":\n",
        "              count_N+=1\n",
        "              index_min2.append((distance2,at_coord[i]))\n",
        "              bond_count.append(count_N)\n",
        "            if distance2 <1.6 and count_N==0 and charge_mode ==\"[M+H]+\":\n",
        "              count_N+=1\n",
        "              index_min2.append((distance2,at_coord[i]))\n",
        "              bond_count.append(count_N)\n",
        "\n",
        "\n",
        "  charge_count=0\n",
        "\n",
        "  for i4 in range(len(index_min2)):\n",
        "    proton_coord.append((index_min2[i4][1]))\n",
        "    fi_name.append(I)\n",
        "    molecule_dict.append((I,index_min2[i4][1]))\n",
        "\n",
        "  for i in range(len(index_min)):\n",
        "    fi_name.append(I)\n",
        "    proton_coord.append((index_min[i][1]))\n",
        "    molecule_dict.append((I,index_min[i][1]))\n",
        "\n",
        "atomic_radi= ({\"C\":1.70, \"O\":1.52, \"H\": 1.20, \"N\":1.55, \"F\":1.35,\"Cl\":1.75,\n",
        "          \"Br\":1.83, \"I\":1.98, \"S\":1.80, \"P\":1.80, \"Se\":1.90})\n",
        "atomic_mass = ({\"C\":12.011, \"O\":15.999, \"H\":1.0080, \"N\":14.007, \"F\":18.99840316,\n",
        "          \"Cl\":35.45,\"Br\":79.9 ,\"I\":126.9045,\"S\":32.07,\"P\":30.97, \"Se\": 78.97})\n",
        "atomic_EN = ({\"C\":2.55, \"O\":3.44, \"H\":2.20, \"N\":3.04, \"F\":3.98,\"Cl\":3.16,\n",
        "          \"Br\":2.96 , \"I\":2.66 ,\"S\":2.58,\"P\":3.15, \"Se\":2.55})\n",
        "atomic_pol = {\"O\":5.3, \"N\":7.4, \"S\":19.4, \"P\":25, \"Se\":29}\n",
        "\n",
        "\n",
        "Name = file_name\n",
        "\n",
        "Halogen_list=[\"F\",\"Cl\",\"Br\",\"I\"]\n",
        "othergen_list=[\"S\",\"P\",\"Se\"]\n",
        "d = len(os.listdir(\"{}/\".format(Name)))\n",
        "id = os.listdir(\"{}/\".format(Name))\n",
        "\n",
        "\n",
        "COM_list1= []\n",
        "try:\n",
        "  id.remove('.ipynb_checkpoints')\n",
        "except ValueError:\n",
        "  pass\n",
        "\n",
        "action_dist1,action_dist2,total_C,total_O=([],[],[],[])\n",
        "total_N,total_H,total_Halogen,total_othergen=([],[],[],[])\n",
        "C,O,N,H,Halo,other,COE_list=(0,0,0,0,0,0,[])\n",
        "\n",
        "\n",
        "for e in range(len(id)):\n",
        "  H_atom,C_atom,O_atom=([],[],[])\n",
        "  N_atom,Halo_atom,other_atom=([],[],[])\n",
        "  if id[e][-3:].lower()!=\"csv\":\n",
        "    xyz_file = open(\"{}/{}\".format(Name, id[e]))\n",
        "    xyz_list=[]\n",
        "    tru_list=[]\n",
        "    for x in xyz_file:\n",
        "      X = x.split()\n",
        "      try:\n",
        "        if X[0].isalpha() and not X[2].isalpha():\n",
        "          xyz_list.append(X)\n",
        "      except IndexError:\n",
        "        next\n",
        "\n",
        "    for a in xyz_list:\n",
        "      if a[0] ==\"H\":\n",
        "        H=+1\n",
        "        H_atom.append(H)\n",
        "      if a[0] ==\"C\":\n",
        "        C=+1\n",
        "        C_atom.append(C)\n",
        "      if a[0] ==\"O\":\n",
        "        O=+1\n",
        "        O_atom.append(O)\n",
        "      if a[0] ==\"N\":\n",
        "        N=+1\n",
        "        N_atom.append(N)\n",
        "      if a[0] in Halogen_list:\n",
        "        Halo=+1\n",
        "        Halo_atom.append(Halo)\n",
        "      if a[0] in othergen_list:\n",
        "        other=+1\n",
        "        other_atom.append(other)\n",
        "\n",
        "    M_x, M_y, M_z, total_EN = EN_moments(a)\n",
        "    EN_COM = center_of_EN(M_x, M_y, M_z, total_EN)\n",
        "\n",
        "    COE_list.append(EN_COM)\n",
        "    total_C.append(sum(C_atom))\n",
        "    total_O.append(sum(O_atom))\n",
        "    total_N.append(sum(N_atom))\n",
        "    total_H.append(sum(H_atom))\n",
        "    total_Halogen.append(sum(Halo_atom))\n",
        "    total_othergen.append(sum(other_atom))\n",
        "\n",
        "    percen_C= (sum(C_atom)/(len(xyz_list)))\n",
        "    percen_O= (sum(O_atom)/(len(xyz_list)))\n",
        "    percen_C= (sum(C_atom)/(len(xyz_list)))\n",
        "    percen_H= (sum(H_atom)/(len(xyz_list)))\n",
        "\n",
        "    dist_list =[]\n",
        "    dist_list2=[]\n",
        "    for n in range(len(xyz_list)):\n",
        "\n",
        "      for n2 in range(len(xyz_list)):\n",
        "\n",
        "        dist = ((((float(xyz_list[n][1])-float(xyz_list[n2][1]))**2)+\n",
        "         ((float(xyz_list[n][2])-float(xyz_list[n2][2]))**2)+\n",
        "          ((float(xyz_list[n][3])-float(xyz_list[n2][3]))**2))**(1/2))\n",
        "        dist_list.append((dist,n,n2,))\n",
        "        dist_list2.append(dist)\n",
        "\n",
        "    far_coor1, far_coor2=xyz_list[max(dist_list)[1]],xyz_list[max(dist_list)[2]]\n",
        "\n",
        "center_of_dict={}\n",
        "for E in range(len(id)):\n",
        "  center_of_dict[id[E]]=COM_List[E],COE_list[E]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ftBPfPIJW_Ur",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Feature Engineering and Extraction\n",
        "\n",
        "import math\n",
        "\n",
        "def find_angle(molecule_dict,center_of_dict):\n",
        "  angle_list=[]\n",
        "  for i in range(len(molecule_dict)):\n",
        "    COM_List=center_of_dict[molecule_dict[i][0]][0]\n",
        "    COE_list=center_of_dict[molecule_dict[i][0]][1]\n",
        "    proton_coord=molecule_dict[i][1]\n",
        "    AB_=float(COE_list[0])-float(proton_coord[1]),float(COE_list[1])-float(proton_coord[2]),float(COE_list[2])-float(proton_coord[3])\n",
        "    BC_=float(proton_coord[1])-COM_List[0],float(proton_coord[2])-COM_List[1],float(proton_coord[3])-COM_List[2]\n",
        "    AB__BC=AB_[0]*BC_[0]+AB_[1]*BC_[1]+AB_[2]*BC_[2]\n",
        "    AB=(AB_[0]**2+AB_[1]**2+AB_[2]**2)**0.5\n",
        "    BC=(BC_[0]**2+BC_[1]**2+BC_[2]**2)**0.5\n",
        "    AB_BC=math.acos((AB__BC)/(AB*BC))*(180/math.pi)\n",
        "    angle_list.append(AB_BC)\n",
        "  return angle_list\n",
        "\n",
        "def distances(molecule_dict,center_of_dict):\n",
        "  distance1=[]\n",
        "  distance2=[]\n",
        "  distance3=[]\n",
        "  for i in range(len(molecule_dict)):\n",
        "    COM_List=center_of_dict[molecule_dict[i][0]][0]\n",
        "    COE_list=center_of_dict[molecule_dict[i][0]][1]\n",
        "    proton_coord=molecule_dict[i][1]\n",
        "    distance_1= (((COE_list[0]-float(proton_coord[1]))**2)+((COE_list[1]-float(proton_coord[2]))**2)+((COE_list[2]-float(proton_coord[3]))**2))\n",
        "    distance_2= (((COM_List[0]-float(proton_coord[1]))**2)+((COM_List[1]-float(proton_coord[2]))**2)+((COM_List[2]-float(proton_coord[3]))**2))\n",
        "    distance_3= (((COE_list[0]-COM_List[0])**2)+((COE_list[1]-COM_List[1])**2)+((COE_list[2]-COM_List[2])**2))\n",
        "    distance1.append(distance_1)\n",
        "    distance2.append(distance_2)\n",
        "    distance3.append(distance_3)\n",
        "  return distance1,distance2,distance3\n",
        "\n",
        "\n",
        "angle_list = find_angle(molecule_dict,center_of_dict)\n",
        "distance1,distance2,distance3 = distances(molecule_dict,center_of_dict)\n",
        "\n",
        "COE_dist_list = distance1\n",
        "COM_dist_list = distance2\n",
        "COM_COE_distance = distance3\n",
        "\n",
        "mol_feats={}\n",
        "for s in range(len(id)):\n",
        "  mol_feats[id[s].split(\".\")[0]]=(surface_area[s],total_O[s],total_N[s],\n",
        "                                  total_Halogen[s],total_othergen[s])\n"
      ],
      "metadata": {
        "id": "t0MRXKT6tJnZ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Generate ML Test Data\n",
        "# training_file = \"Test_charge\" # @param {type:\"string\"}\n",
        "try:\n",
        "  os.mkdir(\"test_data\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  os.rmdir(\"test_data/.ipynb_checkpoints\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "for n in range(len(fi_name)):\n",
        "  mol_name=fi_name[n].split(\".\")[0]\n",
        "  testfile_name='test_data/{}.csv'.format(mol_name)\n",
        "  f = open(testfile_name, 'a')\n",
        "  print(\"{},{},{},{},{},{},{},{},{},{}\".format(atomic_pol[proton_coord[n][0]],\n",
        "       COM_dist_list[n], COE_dist_list[n],COM_COE_distance[n],angle_list[n],\n",
        "       mol_feats[mol_name][0],mol_feats[mol_name][1],mol_feats[mol_name][2],\n",
        "       mol_feats[mol_name][3], mol_feats[mol_name][4]),file=f)\n",
        "  f.close()\n"
      ],
      "metadata": {
        "id": "o8WjOJxjbSNH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Model Preparation and Training\n",
        "import ydf\n",
        "import pandas as pd\n",
        "\n",
        "def weight_option(charge_mode):\n",
        "  if charge_mode ==\"[M+H]+\":\n",
        "    weights= \"COM_Dist\"\n",
        "  else:\n",
        "    weights=\"COM_Dist\"\n",
        "  return weights\n",
        "\n",
        "def learn_depth(charge_mode):\n",
        "  if charge_mode ==\"[M+H]+\":\n",
        "    max_depth= 8\n",
        "  if charge_mode ==\"[M+H]+\" and (sum(total_othergen)>0 or sum(total_Halogen)>0):\n",
        "    max_depth= 10\n",
        "  if charge_mode ==\"[M-H]-\":\n",
        "    max_depth= 10\n",
        "  if charge_mode ==\"[M-H]-\" and (sum(total_othergen)>0 or sum(total_Halogen)>0):\n",
        "    max_depth= 12\n",
        "  return max_depth\n",
        "\n",
        "\n",
        "column_names = (['Atomic_pol','COM_Dist','COE_Dist','COM2COE_Dist','Interaction_Angle',\n",
        "'MSA','Total_O','Total_N','Total_Halogen','Total_Othergen','CCS','Rel_Energy'])\n",
        "reg_data = pd.read_csv(\"{}\".format(train_file), names=column_names)\n",
        "\n",
        "reg_data.pop('CCS')\n",
        "reg_data1 = reg_data.copy()\n",
        "reg_test = reg_data1.pop('Rel_Energy')\n",
        "train_data = reg_data\n",
        "test_data = reg_data\n",
        "\n",
        "model5 = ydf.GradientBoostedTreesLearner(label='Rel_Energy',\n",
        "                                task=ydf.Task.REGRESSION, num_trees=300,\n",
        "    growing_strategy=\"BEST_FIRST_GLOBAL\",\n",
        "    max_depth=learn_depth(charge_mode),\n",
        "    sampling_method=\"RANDOM\",\n",
        "    weights=weight_option(charge_mode),\n",
        "    split_axis=\"SPARSE_OBLIQUE\",\n",
        "    categorical_algorithm=\"RANDOM\",).train(train_data)\n",
        "\n",
        "assert model5.task() == ydf.Task.REGRESSION\n",
        "\n",
        "evaluation = model5.evaluate(test_data)\n",
        "\n",
        "rmse=[]\n",
        "rmse.append(evaluation)\n",
        "rms=[]\n",
        "\n",
        "fi =open(\"rms\", \"w\")\n",
        "for r in rmse:\n",
        "  print(r, file=fi)\n",
        "fi.close()\n",
        "\n",
        "rm =open(\"rms\")\n",
        "for r in rm:\n",
        "  if r.split(\":\")[0]==\"RMSE\":\n",
        "    rms.append(r.split(\":\")[1])\n",
        "\n",
        "rmse_=rms[0].replace(\"\\n\",\"\")\n",
        "\n"
      ],
      "metadata": {
        "id": "15wNHw8gfOhx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Machine Learning Prediction\n",
        "\n",
        "def ML_predict(data_files):\n",
        "  column_names2=(['Atomic_pol','COM_Dist','COE_Dist','COM2COE_Dist',\n",
        "  'Interaction_Angle','MSA','Total_O','Total_N','Total_Halogen', 'Total_Othergen'])\n",
        "  test_data1 =pd.read_csv(\"test_data/{}\".format(data_files), names=column_names2)\n",
        "  test_results={}\n",
        "  reg_pred = model5.predict(test_data1)\n",
        "  test_data1['Predicted_Energy']=reg_pred/float(rmse_)\n",
        "  modified_pred = list(reg_pred/float(rmse_))\n",
        "  return test_data1, modified_pred\n",
        "\n",
        "def get_test_results(modified_pred_dict,molecule_dict, id):\n",
        "  test_results={}\n",
        "  molecule_dict\n",
        "  posit_count=0\n",
        "  for t in range(len(molecule_dict)):\n",
        "    if molecule_dict[t][0]==id:\n",
        "      try:\n",
        "        test_results[modified_pred_dict[id][posit_count]]=molecule_dict[t]\n",
        "        posit_count+=1\n",
        "      except:\n",
        "        posit_count-=1\n",
        "        pass\n",
        "    else:\n",
        "      posit_count=0\n",
        "  return test_results\n",
        "\n",
        "def get_min_score(pred_file,rmse_):\n",
        "  test_data1 =pd.read_csv(\"predict/{}\".format(pred_file))\n",
        "  min_confidence_score =(int(round((min(test_data1['Predicted_Energy'])/\n",
        "  (test_data1['Predicted_Energy'].var()+test_data1['Predicted_Energy'].std())+\n",
        "  (float(rmse_)/3)),0))+0)\n",
        "  if min_confidence_score == 0 :\n",
        "    return 1\n",
        "  else:\n",
        "    return min_confidence_score\n",
        "\n",
        "try:\n",
        "  os.mkdir(\"predict\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "try:\n",
        "  os.rmdir(\"predict/.ipynb_checkpoints\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "modified_pred_list=[]\n",
        "data_files=os.listdir(\"test_data\")\n",
        "modified_pred_dict={}\n",
        "for d in range(len(data_files)):\n",
        "  test_data1, modified_pred= ML_predict(data_files[d])\n",
        "  modified_pred_dict[data_files[d].replace(\"csv\",'xyz')]=modified_pred\n",
        "  modified_pred_list.append(modified_pred)\n",
        "  test_data1.to_csv(\"predict/{}\".format(data_files[d]), index=False)\n",
        "\n",
        "\n",
        "test_results_lis=[]\n",
        "for d in range(len(id)):\n",
        "  test_results = get_test_results(modified_pred_dict,molecule_dict,id[d])\n",
        "  test_results_lis.append(test_results)\n",
        "  pred_file=os.listdir(\"predict\")\n",
        "\n",
        "\n",
        "thresh_list=[]\n",
        "for t in range(len(pred_file)):\n",
        "  thresh_1 = get_min_score(pred_file[t],rmse_)\n",
        "  thresh_list.append(thresh_1)\n",
        "\n",
        "sorted_PE_list=[]\n",
        "for t in range(len(test_results_lis)):\n",
        "  sorted_PE_list.append(sorted(test_results_lis[t].items(), key=lambda item: item[0]))\n",
        "\n",
        "\n",
        "RE_valu_list={}\n",
        "for s in range(len(sorted_PE_list)):\n",
        "  val_count=0\n",
        "  RE_valu=[]\n",
        "  for k,v in sorted_PE_list[s]:\n",
        "    if val_count < thresh_list[s]:\n",
        "      val_count+=1\n",
        "      RE_valu.append(k)\n",
        "  try:\n",
        "    RE_valu_list[sorted_PE_list[s][1][1][0]]= RE_valu\n",
        "  except:\n",
        "    print(\"No viable site found. Run end.\")\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "3YUpySvui-nP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Candidate Charge Site(s) Selection\n",
        "\n",
        "import py3Dmol\n",
        "\n",
        "def get_candidate_coord(RE_valu_list,test_results_lis):\n",
        "  charge_sites=[]\n",
        "  for t in range(len(test_results_lis)):\n",
        "    for k,v in test_results_lis[t].items():\n",
        "      for t in RE_valu_list:\n",
        "        if k in RE_valu_list[t]:\n",
        "          charge_sites.append((k,v))\n",
        "  return charge_sites\n",
        "\n",
        "def find_distance(sites,coord):\n",
        "  try:\n",
        "    x = float(coord[1]) - float(sites[1])\n",
        "    y = float(coord[2]) - float(sites[2])\n",
        "    z = float(coord[3]) - float(sites[3])\n",
        "    distance4 = (x**2 + y**2 + z**2)**0.5\n",
        "    return distance4\n",
        "  except:\n",
        "    x = float(coord[0]) - float(sites[1])\n",
        "    y = float(coord[1]) - float(sites[2])\n",
        "    z = float(coord[2]) - float(sites[3])\n",
        "    distance4 = (x**2 + y**2 + z**2)**0.5\n",
        "    return distance4\n",
        "\n",
        "def bonded_distance(s):\n",
        "  at_coord2 = open(file_name +\"/\"+s[0])\n",
        "  bonded =[]\n",
        "  for aa in at_coord2:\n",
        "    if len(aa.split())>3:\n",
        "      a=aa.split()\n",
        "      dist = find_distance(s[1],a)\n",
        "      if 0.7<float(dist) <1.8:\n",
        "        bonded.append((s,a))\n",
        "  return bonded\n",
        "\n",
        "def nonbonded_distance(bonded_atom,new_H_coor):\n",
        "  atom_B = bonded_atom[0][1]\n",
        "  atom_C = new_H_coor\n",
        "  distance = ((((float(atom_B[1])-float(atom_C[0]))**2)+((float(atom_B[2])-\n",
        "  float(atom_C[1]))**2)+((float(atom_B[3])-float(atom_C[2]))**2))**(1/2))\n",
        "  return distance\n",
        "\n",
        "def H_C_N_distance(new_H_coor):\n",
        "  H_dist_list=[]\n",
        "  C_dist_list=[]\n",
        "  N_dist_list=[]\n",
        "  Hot_dist_list=[]\n",
        "  at_coord2 = open(file_name +\"/\"+s[0])\n",
        "  for aa in at_coord2:\n",
        "    if len(aa.split())>3:\n",
        "      a=aa.split()\n",
        "      if a[0] ==\"H\":\n",
        "        dist_H = find_distance(a,new_H_coor)\n",
        "        H_dist_list.append(dist_H)\n",
        "      if a[0] ==\"C\":\n",
        "        dist_C = find_distance(a,new_H_coor)\n",
        "        C_dist_list.append(dist_C)\n",
        "      if a[0] ==\"N\":\n",
        "        dist_N = find_distance(a,new_H_coor)\n",
        "        N_dist_list.append(dist_N)\n",
        "      try:\n",
        "        if a[0] ==[o for o in othergen_list if a[0] in o][0]:\n",
        "          dist_Hot = find_distance(a,new_H_coor)\n",
        "          Hot_dist_list.append(dist_Hot)\n",
        "        else:\n",
        "          Hot_dist_list.append(10)\n",
        "      except:\n",
        "        pass\n",
        "  return H_dist_list,C_dist_list,N_dist_list,Hot_dist_list\n",
        "\n",
        "def bonded_angle(bonded_atom,new_H_coor):\n",
        "  atom_A = bonded_atom[0][0][1]\n",
        "  atom_B = bonded_atom[0][1]\n",
        "  atom_C = new_H_coor\n",
        "  AB_=(float(atom_A[1])-float(atom_B[1]),float(atom_A[2])-float(atom_B[2]),\n",
        "       float(atom_A[3])-float(atom_B[3]))\n",
        "  BC_=(float(atom_B[1])-float( atom_C [0]),float(atom_B[2])-float( atom_C [1]),\n",
        "       float(atom_B[3])-float( atom_C [2]))\n",
        "  AB__BC=AB_[0]*BC_[0]+AB_[1]*BC_[1]+AB_[2]*BC_[2]\n",
        "  AB=(AB_[0]**2+AB_[1]**2+AB_[2]**2)**0.5\n",
        "  BC=(BC_[0]**2+BC_[1]**2+BC_[2]**2)**0.5\n",
        "  AB_BC=math.acos((AB__BC)/(AB*BC))*(180/math.pi)\n",
        "  bond_angle = AB_BC\n",
        "  return bond_angle\n",
        "\n",
        "def new_proton_coord(molec_lib, angle_increment,act):\n",
        "  x_vertex=float(molec_lib[1])\n",
        "  y_vertex=float(molec_lib[2])\n",
        "  z_vertex=float(molec_lib[3])\n",
        "  if molec_lib[0] == \"O\":\n",
        "    r=0.95\n",
        "  if molec_lib[0] == \"N\":\n",
        "    r=1.0\n",
        "  x,y,z,r=0,0,0,r\n",
        "  theta = math.acos(0)\n",
        "  phi = math.atan(0)\n",
        "  deg = 70 + angle_increment\n",
        "  rad = deg * (math.pi/180)\n",
        "  theta = rad+theta\n",
        "  if act == 0:\n",
        "    phi = 0.10 - math.sin(theta/(angle_increment*0.01+.01))\n",
        "  else:\n",
        "    phi = 0.10 + math.cos(theta/act)\n",
        "  x_= r*math.sin(theta)*math.cos(phi)\n",
        "  y_= r*math.sin(theta)*math.sin(phi)\n",
        "  z_= r*math.cos(theta)\n",
        "  x_new=float(x_)+x_vertex\n",
        "  y_new=float(y_)+y_vertex\n",
        "  z_new=float(z_)+z_vertex\n",
        "  return x_new,y_new,z_new\n",
        "\n",
        "\n",
        "charge_sites= get_candidate_coord(RE_valu_list,test_results_lis)\n",
        "\n",
        "sorted_charge_sites=[]\n",
        "for c in sorted(charge_sites):\n",
        "  sorted_charge_sites.append(c[1])\n",
        "\n",
        "\n",
        "de_proton_coord =[]\n",
        "if charge_mode == \"[M-H]-\":\n",
        "  for s in sorted_charge_sites:\n",
        "    bond_dist = bonded_distance(s)\n",
        "    countH=0\n",
        "    for b in bond_dist:\n",
        "      if b[1][0] ==\"H\" and countH<1:\n",
        "        de_proton_coord.append((b[0][0],b[1]))\n",
        "        countH+=1\n",
        "tot_bond=[]\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  for s2 in sorted_charge_sites:\n",
        "    bond_dist = bonded_distance(s2)\n",
        "    countH=0\n",
        "    for b in bond_dist:\n",
        "      if b[1][0] !=\"N\" :\n",
        "        countH+=1\n",
        "    tot_bond.append(countH)\n",
        "\n",
        "\n",
        "molec_lib={}\n",
        "angle_increment = 0\n",
        "count_chk = 0\n",
        "protonated_sites_list =[]\n",
        "reduntant_list=[]\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  for s in sorted_charge_sites:\n",
        "\n",
        "    if sorted_charge_sites[count_chk][1][0] ==\"N\" and tot_bond[count_chk]>3:\n",
        "      count_chk+=1\n",
        "      pass\n",
        "    else:\n",
        "      act=0\n",
        "      angle_increment = 0\n",
        "      molec_lib = s[1]\n",
        "\n",
        "      x_new,y_new,z_new= new_proton_coord(molec_lib, angle_increment,act)\n",
        "      new_H_coor = [x_new,y_new,z_new]\n",
        "      bonded_atom = bonded_distance(s)\n",
        "      bond_angle = bonded_angle(bonded_atom,new_H_coor)\n",
        "      bond_dist2 = find_distance(s[1],new_H_coor)\n",
        "      tot_iteration = []\n",
        "      count_iter=0\n",
        "      while 0 < bond_angle <=360:\n",
        "        angle_increment+=1\n",
        "        x_new,y_new,z_new= new_proton_coord(molec_lib, angle_increment,act)\n",
        "        new_H_coor = [x_new,y_new,z_new]\n",
        "        bonded_atom = bonded_distance(s)\n",
        "        bond_angle = bonded_angle(bonded_atom,new_H_coor)\n",
        "        nb_dist = nonbonded_distance(bonded_atom,new_H_coor)\n",
        "        H_dist_list,C_dist_list,N_dist_list,Hot_dist_list = H_C_N_distance(new_H_coor)\n",
        "        try:\n",
        "          test_empty=min(Hot_dist_list)\n",
        "        except:\n",
        "          Hot_dist_list.append(10)\n",
        "\n",
        "        count_iter=+1\n",
        "        chk1,chk2,chk3,chk4,chk5=0,0,0,0,0\n",
        "        tot_iteration .append(count_iter)\n",
        "        if sum(tot_iteration ) < 2000:\n",
        "          try:\n",
        "            if (90 < bond_angle < 160 and nb_dist > 1.8 and\n",
        "              min(Hot_dist_list) > 1.5 and min(C_dist_list) > 1.75 and min(N_dist_list) > 0.95 ):\n",
        "              count_iter=0\n",
        "              break\n",
        "          except:\n",
        "            (90 < bond_angle < 160 and nb_dist > 1.8 and\n",
        "            min(Hot_dist_list) > 1.5 and min(C_dist_list) > 1.75 )\n",
        "            break\n",
        "        if 3000 > sum(tot_iteration ) > 2000:\n",
        "          act += 1\n",
        "          try:\n",
        "            if (100 < bond_angle < 160  and nb_dist > 1.8 and min(H_dist_list) > 1.5 and\n",
        "              min(Hot_dist_list)>1.5 and min(C_dist_list) > 1.75 and min(N_dist_list) > 0.95 ):\n",
        "              count_iter=0\n",
        "              break\n",
        "          except:\n",
        "            if (100 < bond_angle < 160  and nb_dist > 1.8 and min(H_dist_list) > 1.5 and\n",
        "              min(Hot_dist_list)>1.5 and min(C_dist_list) > 1.75):\n",
        "              break\n",
        "        if 4000 > sum(tot_iteration ) > 3000:\n",
        "          act+=1\n",
        "          if (90 < bond_angle < 160  and nb_dist > 1.8 and min(Hot_dist_list)>1.5\n",
        "              and min(H_dist_list) > 1.5 and min(C_dist_list) > 1.6 ):\n",
        "            count_iter=0\n",
        "            break\n",
        "        if 5000 > sum(tot_iteration ) > 4000:\n",
        "          if (90 < bond_angle < 160 and min(H_dist_list) > 1.5 and min(Hot_dist_list)>1.5\n",
        "              and min(C_dist_list) > 1.6 and nb_dist > 1.4):\n",
        "            count_iter=0\n",
        "            break\n",
        "        if 6000 > sum(tot_iteration ) > 5000:\n",
        "          act=0\n",
        "          if (90 < bond_angle < 180 and min(H_dist_list) > 1.4\n",
        "              and min(C_dist_list) > 1.6 and min(Hot_dist_list)>1.4):\n",
        "            count_iter=0\n",
        "            break\n",
        "        if 7000 > sum(tot_iteration ) > 6000 :\n",
        "          act += 1\n",
        "          try:\n",
        "            if (90 < bond_angle < 160 and min(H_dist_list) > 1.5 and min(Hot_dist_list)>1.5\n",
        "                and min(C_dist_list) > 1.6 and min(N_dist_list) > 0.95):\n",
        "              count_iter=0\n",
        "              break\n",
        "          except:\n",
        "            if (90 < bond_angle < 160 and min(H_dist_list) > 1.5 and min(Hot_dist_list)>1.5\n",
        "                and min(C_dist_list) > 1.6):\n",
        "              break\n",
        "\n",
        "        if sum(tot_iteration ) > 7000:\n",
        "          act=0\n",
        "          if (90 < bond_angle < 200 and min(H_dist_list)>1.4\n",
        "              and min(C_dist_list) > 1.4 and min(Hot_dist_list)>1.4):\n",
        "            count_iter=0\n",
        "            chk1=1\n",
        "            break\n",
        "          act+=1/2\n",
        "          if (80 < bond_angle < 180 and min(H_dist_list)>1.3\n",
        "              and min(C_dist_list) > 1.5 and min(Hot_dist_list)>1.5 and chk1==0):\n",
        "            count_iter=0\n",
        "            chk2=1\n",
        "            break\n",
        "          act+=1\n",
        "          if (70 < bond_angle < 180 and min(H_dist_list) > 1.3\n",
        "              and min(C_dist_list) > 1.5 and min(Hot_dist_list)>1.5 and chk2==0):\n",
        "            count_iter=0\n",
        "            act=0\n",
        "            chk3=1\n",
        "            break\n",
        "          act-=1/2\n",
        "          if (70 < bond_angle < 180 and min(H_dist_list) > 1.3\n",
        "              and min(C_dist_list) > 1.6 and min(Hot_dist_list)>1.5 and chk3==0):\n",
        "            count_iter=0\n",
        "            chk4=1\n",
        "            break\n",
        "          act+=1/3\n",
        "          if (70 < bond_angle < 180 and min(H_dist_list) > 1.2\n",
        "              and min(C_dist_list) > 1.5 and min(Hot_dist_list)>1.5 and chk4==0):\n",
        "            count_iter=0\n",
        "            chk5=1\n",
        "            break\n",
        "          act+=math.log(angle_increment)\n",
        "          if (70 < bond_angle < 200 and min(H_dist_list) > 1.2\n",
        "              and min(C_dist_list) > 1.5 and min(Hot_dist_list)>1.5 and chk5==0):\n",
        "            count_iter=0\n",
        "            break\n",
        "\n",
        "      count_chk+=1\n",
        "      protonated_sites_list.append((s,new_H_coor))\n",
        "\n"
      ],
      "metadata": {
        "id": "J7JecnLsUMqx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Generate Initial Charge Model Ranking\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "if charge_mode == \"[M-H]-\":\n",
        "  rename_ =de_proton_coord[0][0].replace(\".xyz\",\"\").replace(\"_\",\"-\")\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  rename_ =protonated_sites_list[0][0][0].replace(\".xyz\",\"\").replace(\"_\",\"-\")\n",
        "\n",
        "try:\n",
        "  folder_name = \"Completed_Job\"\n",
        "  os.mkdir(folder_name)\n",
        "except:\n",
        "  folder_name = \"Completed_Job\"\n",
        "try:\n",
        "  os.mkdir(\"{}/{}\".format(folder_name,rename_ ))\n",
        "except:\n",
        "  try:\n",
        "    os.remove(\"{}/{}\".format(folder_name,rename_ ))\n",
        "  except:\n",
        "    try:\n",
        "      os.mkdir(\"{}/{}\".format(folder_name,rename_ ))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "unsupported_atoms = [\"Br\", \"I\", \"P\", \"Se\"]\n",
        "switch_atom_lib={}\n",
        "rank = 0\n",
        "if charge_mode == \"[M-H]-\":\n",
        "  for p in range(len(de_proton_coord)):\n",
        "    rank+=1\n",
        "    fi_nam = open(file_name+\"/{}\".format(de_proton_coord[p][0]))\n",
        "    fo_name = open(\"{}/{}/{}_rank{}_model.xyz\".format(folder_name,\n",
        "                  rename_,rename_,rank ),'a')\n",
        "    for f in fi_nam:\n",
        "      if f.split()[0].isnumeric():\n",
        "        tot_atom = f.split()[0]\n",
        "        update_tot = int(tot_atom)-1\n",
        "        print(update_tot,file=fo_name)\n",
        "        print(rename_+\"_rank{}\".format(rank),file=fo_name)\n",
        "      if len(f.split())>3:\n",
        "        if f.split()==de_proton_coord[p][1]:\n",
        "          pass\n",
        "        else:\n",
        "          if f.split()[0] not in unsupported_atoms:\n",
        "            print(f.strip(),file=fo_name)\n",
        "          if f.split()[0] !=\"S\" and (f.split()[0] == \"P\" or f.split()[0] == \"Se\"):\n",
        "            switch_atom_lib[\"S\"]=f.split()[0]\n",
        "            print(f.strip().replace(f.split()[0],\"S\"),file=fo_name)\n",
        "          if f.split()[0] not in [\"F\",\"Cl\"] and (f.split()[0] == \"Br\" or f.split()[0] ==\"I\"):\n",
        "            switch_atom_lib[\"Cl\"]=f.split()[0]\n",
        "            print(f.strip().replace(f.split()[0],\"Cl\"),file=fo_name)\n",
        "    fo_name.close()\n",
        "\n",
        "\n",
        "if charge_mode == \"[M+H]+\":\n",
        "  for p in range(len(protonated_sites_list)):\n",
        "    rank+=1\n",
        "    x_up, y_up, z_up = (float(protonated_sites_list[p][1][0]),\n",
        "    float(protonated_sites_list[p][1][1]),float(protonated_sites_list[p][1][2]))\n",
        "    fi_nam = open(file_name+\"/{}\".format(protonated_sites_list[p][0][0]))\n",
        "    fo_name = open(\"{}/{}/{}_rank{}_model.xyz\".format(folder_name,\n",
        "                  rename_,rename_,rank),'a')\n",
        "    for f in fi_nam:\n",
        "      if f.split()[0].isnumeric():\n",
        "        tot_atom = f.split()[0]\n",
        "        update_tot = int(tot_atom)+1\n",
        "        print(update_tot,file=fo_name)\n",
        "        print(rename_+\"_rank{}\".format(rank),file=fo_name)\n",
        "      if len(f.split())>3:\n",
        "        if f.split()[0] not in unsupported_atoms:\n",
        "          print(f.strip(),file=fo_name)\n",
        "        if f.split()[0] !=\"S\" and (f.split()[0] == \"P\" or f.split()[0] == \"Se\"):\n",
        "          switch_atom_lib[\"S\"]=f.split()[0]\n",
        "          print(f.strip().replace(f.split()[0],\"S\"),file=fo_name)\n",
        "        if f.split()[0] not in [\"F\",\"Cl\"] and (f.split()[0] == \"Br\" or f.split()[0] ==\"I\"):\n",
        "          switch_atom_lib[\"Cl\"]=f.split()[0]\n",
        "          print(f.strip().replace(f.split()[0],\"Cl\"),file=fo_name)\n",
        "        if f.split()==protonated_sites_list[p][0][1]:\n",
        "          print(\"{:<1}{:17.5f}{:^22.5f}{:^4.5f}\".format(\"H\",\n",
        "                x_up, y_up, z_up), file=fo_name)\n",
        "    fo_name.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "V62bGZ8ziqgf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Charge Model ANI Geometry Optimization\n",
        "import mlatom as ml\n",
        "import ase\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  os.remove(testfile_name)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "Name_in = folder_name+\"/\"+rename_\n",
        "d = len(os.listdir(Name_in+\"/\" ))\n",
        "id = os.listdir(Name_in+\"/\" )\n",
        "spe={}\n",
        "try:\n",
        "  id.remove('.ipynb_checkpoints')\n",
        "  d = len(id)\n",
        "except:\n",
        "  pass\n",
        "for i in range(d):\n",
        "  if id[i][-3:].lower()!=\"csv\":\n",
        "    try:\n",
        "      supported =\"yes\"\n",
        "      mole_id =(\"{}/{}\".format(Name_in,id[i]))\n",
        "      method_=\"ANI-2x\"\n",
        "      ani = ml.models.methods(method=method_,)\n",
        "      in_mol = ml.data.molecule.from_xyz_file('{}'.format(mole_id))\n",
        "      cut_link = mole_id.split(\"/\")\n",
        "      opt_name='opt-{}*$'.format(cut_link[2])\n",
        "      OPT_fi = cut_link[0]+\"/\"+cut_link[1]+\"/\"+opt_name\n",
        "      OPT_mol = (ml.optimize_geometry(model=ani, initial_molecule=in_mol,\n",
        "              program=\"ASE\", maximum_number_of_steps=50).optimized_molecule)\n",
        "      OPT_mol.xyz_coordinates\n",
        "\n",
        "      OPT_mol.get_xyz_string()\n",
        "      OPT_mol.write_file_with_xyz_coordinates(filename=OPT_fi)\n",
        "\n",
        "    except:\n",
        "      supported =\"no\"\n",
        "      pass\n",
        "\n",
        "  try:\n",
        "    spe[id[i]] = OPT_mol.energy\n",
        "  except:\n",
        "    pass\n",
        "if supported !=\"yes\":\n",
        "  pass\n",
        "else:\n",
        "  for I in id:\n",
        "    if 'opt' not in I:\n",
        "      os.remove(\"{}/{}\".format(Name_in,I))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lyh44H2KD2o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Single-Point Energy Charge Model Ranking Amendment\n",
        "\n",
        "def revert_to_save(revert_,switch_atom_lib,file_link ):\n",
        "  new_file_name = open(file_link.replace(\"*$\",\"\"), \"w\")\n",
        "  for r in revert_:\n",
        "    atom_ = r.split()[0]\n",
        "    if len(r.split())==1 and \"rank\" in r.split()[0]:\n",
        "      try:\n",
        "        print(r.strip().replace(r.split()[0],\n",
        "              \"model_energy_{}\".format(spe[r.split()[0]+\"_model.xyz\"])),\n",
        "              file=new_file_name)\n",
        "      except:\n",
        "        pass\n",
        "    if len(r.split())>3 and (atom_ in Halogen_list or atom_ in othergen_list):\n",
        "      try:\n",
        "        print(r.strip().replace(atom_,switch_atom_lib[atom_]),\n",
        "              file=new_file_name)\n",
        "      except:\n",
        "        print(r.strip(), file=new_file_name)\n",
        "    else:\n",
        "      if \"rank\" not in r.split()[0]:\n",
        "        print(r.strip(), file=new_file_name)\n",
        "  new_file_name.close()\n",
        "\n",
        "\n",
        "if supported !=\"yes\":\n",
        "  pass\n",
        "else:\n",
        "  SPE= sorted(spe.items(), key=lambda x: x[1])\n",
        "  rank_lib = {}\n",
        "  for i in range(len(SPE)):\n",
        "    rank_lib[SPE[i][0].split(\"_\")[1]]=\"Rank{}\".format(i+1)\n",
        "  rank_lib\n",
        "  xyz_name = os.listdir(Name_in)\n",
        "  xyz_name = sorted(xyz_name)\n",
        "  try:\n",
        "    xyz_name.remove('.ipynb_checkpoints')\n",
        "  except:\n",
        "    pass\n",
        "  for x in xyz_name:\n",
        "    try:\n",
        "      keyy = x.split(\"_\")[1]\n",
        "      old_ranking = x\n",
        "      new_ranking = x.replace((keyy), rank_lib[keyy])\n",
        "      os.rename(\"{}/{}\".format(Name_in,old_ranking),\n",
        "                \"{}/{}\".format(Name_in,new_ranking) )\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "revert_file = os.listdir(Name_in)\n",
        "try:\n",
        "    revert_file.remove('.ipynb_checkpoints')\n",
        "except:\n",
        "  pass\n",
        "for r in revert_file:\n",
        "  file_link = \"{}/{}\".format(Name_in, r)\n",
        "  revert_ =open(file_link)\n",
        "  save = revert_to_save(revert_,switch_atom_lib,file_link )\n",
        "  try:\n",
        "    if \"*$\" in file_link:\n",
        "      os.remove(file_link)\n",
        "    else:\n",
        "      pass\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "end = timer()\n",
        "time_complete = datetime.now(pytz.timezone('America/Los_Angeles')).strftime(\"%H:%M:%S     %d-%b-%Y\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SL7YjVmEssi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Ranked charge model(s) and preliminary results summary log\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "def get_mol_fract(rel_E, m, mm):\n",
        "  for m2 in mm:\n",
        "    mol_fract = m2/sum(m)\n",
        "    return mol_fract\n",
        "\n",
        "def get_runtime(end,start):\n",
        "  time_elapse = (end-start)/60\n",
        "  time_elapse=str(time_elapse)\n",
        "  min_,sec_ = (int((time_elapse.split(\".\"))[0]),\n",
        "               int((time_elapse.split(\".\"))[1]))\n",
        "  return min_,sec_\n",
        "\n",
        "\n",
        "min_,sec_ = get_runtime(end,start)\n",
        "\n",
        "bbe = open(Name_in+\"/results_sum.log\", \"w\")\n",
        "print(\"__________________________________________________\\n\", file=bbe)\n",
        "print(\"  .::âˆˆâˆˆâˆˆâˆˆâˆˆ     .:âˆˆâˆˆâˆˆâˆˆâˆˆâˆˆ     .:âˆˆâˆˆâˆˆâˆˆâˆˆâˆˆ   ||âˆˆâˆˆâˆˆâˆˆâˆˆâˆˆ:.\", file=bbe)\n",
        "print(\" '''          ''           ''          |||    '''\", file=bbe)\n",
        "print(\" '::         '''          '''          |||    '''\", file=bbe)\n",
        "print(\"  ':|||::.   ||||||||||   ||||||||||   ||| ..::'\", file=bbe)\n",
        "print(\"       '''   '''          '''          |||  \\\\ \\ \", file=bbe)\n",
        "print(\"       '''    ''.          ''.         |||   \\\\ \\ \", file=bbe)\n",
        "print(\" âˆˆâˆˆâˆˆâˆˆâˆˆ::'      ':âˆˆâˆˆâˆˆâˆˆâˆˆâˆˆ     ':âˆˆâˆˆâˆˆâˆˆâˆˆâˆˆ   |||    \\\\ \\ \\n\", file=bbe)\n",
        "\n",
        "print(\"   State      Ensemble       Energy    Recognition\\n__________________________________________________\",\n",
        "      file=bbe)\n",
        "print(\"==================================================\\nSâˆˆâˆˆR:           Model MK1.0            09-Sep-2024\\n==================================================\",\n",
        "      file=bbe)\n",
        "print(\"Documentation website:\\nhttps://github.com/mitkeng/SEER\", file=bbe)\n",
        "print(\"\\n\\nTo cite this work use:\\nSâˆˆâˆˆR Version 1.0,\\nM. Keng and K. M., Jr. Merz, 2024\\n\",\n",
        "      file=bbe)\n",
        "print(\"Code and interface:\\nM. Keng \\n\\n\", file=bbe)\n",
        "print(\"\\nStart time:{:>38}\".format(time_initiated), file=bbe)\n",
        "print(\"Completed time:{:>34}\".format(time_complete), file=bbe)\n",
        "print(\"Runtime:{:>20}{:02d}:{}\".format(\"\",min_,str(sec_)[:2].split()[0]), file=bbe)\n",
        "print(\"\\n\\n\\nTest system: {}\\nCharge mode: {}\\nOptimization method: {}\\n\\n**************** Results Summary ****************\\n\\n  Test ID         Energy       Rel. E      Mole\".format(id[0].split(\"_\")[0],\n",
        "      charge_mode, method_) ,file=bbe)\n",
        "print(\"{:>25}{:>14}{:>9}\\n-------------------------------------------------\".format(\"(hartree)\",\n",
        "     \"(kcal/mol)\",\"Frac.\"),file=bbe)\n",
        "\n",
        "spe = dict(sorted(spe.items(), key = lambda item: item[1]))\n",
        "\n",
        "test_id_list =[]\n",
        "hart_E=[]\n",
        "m = []\n",
        "mm = []\n",
        "rel_E=[]\n",
        "for k,v in spe.items():\n",
        "  RE= (-min(spe.values())+spe[k])*627.5\n",
        "  rel_E.append(RE)\n",
        "  a = RE/(0.001986*298)\n",
        "  b = math.exp(-1*a)\n",
        "  mm.append(b)\n",
        "  m.append(b)\n",
        "  test_id_list.append(rank_lib[k.split(\"_\")[1]])\n",
        "  hart_E.append(round(v,4))\n",
        "\n",
        "\n",
        "mol_fract=[]\n",
        "for m2 in mm:\n",
        "  mol_fract.append(m2/sum(m))\n",
        "\n",
        "for E in range(len(hart_E)):\n",
        "   (print(\"{:<10}{:^19}{:^10}{:^11}\".format(\"Model \"+test_id_list[E],hart_E[E],\n",
        "    round(rel_E[E],2),round(mol_fract[E],2)), file=bbe))\n",
        "\n",
        "\n",
        "bbe.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "Mr_xC5n1B35W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Charge Model Conformation Generation**"
      ],
      "metadata": {
        "id": "CXItAsnGPxOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### <br/>Model rank 1 charge state:\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from openbabel import pybel\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "\n",
        "\n",
        "\n",
        "def xyz_to_smiles(xyz_file):\n",
        "  try:\n",
        "    mol = next(pybel.readfile(\"xyz\", xyz_file))\n",
        "    return mol.write(\"smi\").split()[0].strip()\n",
        "  except:\n",
        "    return \"None\"\n",
        "\n",
        "\n",
        "def rotatable_bonds(smiles):\n",
        "  try:\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return \"None\"\n",
        "\n",
        "\n",
        "    return rdMolDescriptors.CalcNumRotatableBonds(mol)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "\n",
        "ss= os.listdir(Name_in)\n",
        "try:\n",
        "  ss.remove(\".ipynb_checkpoints\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "for s in ss:\n",
        "  if s.split(\".\")[-1]==\"xyz\" and \"Rank1\" in s.split(\"_\"):\n",
        "    count=0\n",
        "    xyz = open(Name_in+\"/{}\".format(s)).read()\n",
        "    xyzview = py3Dmol.view(width=800,height=300)\n",
        "    xyzview.addModel(xyz,'xyz',{'vibrate': {'frames':1000,'amplitude':1}})\n",
        "    xyzview.setStyle({'stick':{}})\n",
        "    xyzview.setBackgroundColor('white')\n",
        "    xyzview\n",
        "    xyzview.show()\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "Z_folder = \"/content/Completed_Job/{}/conformer/charge_model\".format(molecule_name)\n",
        "try:\n",
        "  os.mkdir(Z_folder)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n",
        "Z_folder = \"/content/Completed_Job/{}/charge_model\".format(molecule_name)\n",
        "try:\n",
        "  os.mkdir(Z_folder)\n",
        "except:\n",
        "  pass\n",
        "Z_files = \"/content/Completed_Job/{}\".format(molecule_name)\n",
        "for d in os.listdir(Z_files):\n",
        "\n",
        "  if \".xyz\" in d:\n",
        "    try:\n",
        "      Z_link = Z_files+\"/\"+d\n",
        "      shutil.copy(Z_link, Z_folder)\n",
        "\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "smi_file= open(Z_folder+\"/smile_list.csv\",\"a\")\n",
        "print(\"Rank,SMILE\", file=smi_file)\n",
        "for s in os.listdir(Z_folder):\n",
        "\n",
        "  smiles = xyz_to_smiles(Z_folder +\"/\"+s)\n",
        "  smi_file = open(Z_folder+\"/smile_list.csv\",\"a\")\n",
        "  if smiles !=\"None\":\n",
        "\n",
        "    print(s.split(\"_\")[-2][4:],\",\",smiles, file=smi_file)\n",
        "    smi_file.close()\n",
        "\n",
        "\n",
        "\n",
        "num_rotbond = rotatable_bonds(smiles)\n",
        "if num_rotbond ==\"None\":\n",
        "  num_rotbond = rotatable_bonds(smile)\n",
        "\n",
        "# if charge_model_download == True:\n",
        "#   shutil.make_archive(Z_folder, 'zip', Z_folder)\n",
        "#   files.download(\"{}.zip\".format(Z_folder))"
      ],
      "metadata": {
        "id": "D6ZP-sRl3Cv8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "def conf_gen(ss,Name_in):\n",
        "  for s in ss:\n",
        "    if s.split(\".\")[-1]==\"xyz\":\n",
        "      B=1000\n",
        "      file = Name_in+\"/{}\".format(s)\n",
        "      conf_folder= Name_in+\"/conformer/\"\n",
        "      conf_file = Name_in+\"/conformer/{}\".format(s)\n",
        "      !mkdir $conf_folder\n",
        "      !obabel $file -O $conf_file --conformer --nconf $B --writeconformers\n",
        "  return conf_folder\n",
        "\n",
        "def partition_xyz(conf_folder):\n",
        "  file_lis = os.listdir(conf_folder)\n",
        "  fi_count=0\n",
        "  for fi in file_lis:\n",
        "    try:\n",
        "      ff = open(conf_folder+\"{}\".format(fi))\n",
        "      conf_dir = conf_folder+\"{}\".format(fi.replace(\"_model.xyz\",\"_conformer\"))\n",
        "    except:\n",
        "      pass\n",
        "    try:\n",
        "      os.mkdir(conf_dir)\n",
        "    except:\n",
        "      pass\n",
        "    num_count=0\n",
        "    for f in ff:\n",
        "      fi_count=0\n",
        "      if f.split()[0].isnumeric():\n",
        "        num_count+=1\n",
        "        fi_count+=1\n",
        "        c_fi = open(conf_dir+\"/{}.xyz\".format(num_count),'a')\n",
        "      if fi_count <=1:\n",
        "        print(f.strip(),file=c_fi)\n",
        "    c_fi.close()\n",
        "    try:\n",
        "      shutil.rmtree(conf_folder+\"{}\".format(fi))\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "generate=conf_gen(ss,Name_in)\n",
        "partition_conf =  partition_xyz(generate)"
      ],
      "metadata": {
        "id": "tkPw6IMR5OYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Empirical Focusing**"
      ],
      "metadata": {
        "id": "yUDRkZZR-7HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "import os, re\n",
        "import statistics as st\n",
        "import shutil\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "#@markdown ### Enter a reference CCS value to initiate empirical space focusing. Enter 0 if no reference is available.\n",
        "#@markdown <br/>\n",
        "\n",
        "Experimental_CCS = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter a value\"}\n",
        "Experimental_CCS = float(Experimental_CCS)\n",
        "\n",
        "\n",
        "dnn_model = tf.keras.models.load_model('ML_ccs.keras')\n",
        "\n",
        "Name = generate\n",
        "system_conf = os.listdir(generate)\n",
        "\n",
        "reduce_list = []\n",
        "\n",
        "for Co in system_conf:\n",
        "  if 'conformer' not in Co:\n",
        "    try:\n",
        "      os.remove(\"{}{}\".format(Name,Co))\n",
        "    except:\n",
        "      pass\n",
        "  try:\n",
        "    if 'conformer' in Co:\n",
        "      d = len(os.listdir(\"{}{}\".format(Name,Co)))\n",
        "      id = os.listdir(\"{}{}\".format(Name,Co))\n",
        "      COM_list= []\n",
        "      mass_list=[]\n",
        "      conf_num=[]\n",
        "      surface_area=[]\n",
        "      for i in range(d):\n",
        "        mol = ase.io.read(\"{}{}/{}\".format(Name,Co,id[i]))\n",
        "        COM = mol.get_center_of_mass(scaled=False)\n",
        "        COM_list.append(COM)\n",
        "        mol_mass = mol.get_masses()\n",
        "        mass_list.append(sum(mol_mass))\n",
        "        cmd.load(\"{}{}/{}\".format(Name,Co,id[i]))  # use the name of your pdb file\n",
        "        cmd.set('dot_solvent', 0)\n",
        "        cmd.set('dot_density',2)\n",
        "        new_id=re.sub(\"[^0-9]\", \"\", id[i])\n",
        "        conf_num.append(new_id)\n",
        "        sa=cmd.get_area('all')\n",
        "        surface_area.append(sa)\n",
        "        cmd.reinitialize()\n",
        "      cmd.reinitialize()\n",
        "\n",
        "      COM_List=[]\n",
        "      for co in COM_list:\n",
        "        COM_List.append((co[0],co[1],co[2]))\n",
        "\n",
        "      electro_neg=  ({\"C\":2.55, \"O\":3.44, \"H\":2.20, \"N\":3.04, \"F\":3.98,\"Cl\":3.16,\n",
        "            \"Br\":2.96 , \"I\":2.66 ,\"S\":2.58,\"P\":3.15, \"Se\":2.55})\n",
        "\n",
        "      d = len(os.listdir(\"{}\".format(Name)))\n",
        "      id = os.listdir(\"{}\".format(Name))\n",
        "\n",
        "      for c in id:\n",
        "        if c[-3:].lower()==\"csv\":\n",
        "          csv_name = c\n",
        "\n",
        "      COM_list1= []\n",
        "      try:\n",
        "        id.remove('.ipynb_checkpoints')\n",
        "      except ValueError:\n",
        "        pass\n",
        "      action_dist1=[]\n",
        "      action_dist2=[]\n",
        "      total_hetero=[]\n",
        "      for e in range(len(conf_num)):\n",
        "\n",
        "          xyz_file = open(\"{}{}/{}.xyz\".format(Name,Co,conf_num[e]))\n",
        "          xyz_list=[]\n",
        "          tru_list=[]\n",
        "          for x in xyz_file:\n",
        "            X = x.split()\n",
        "            try:\n",
        "              if X[0].isalpha() and not X[2].isalpha():\n",
        "                xyz_list.append(X)\n",
        "\n",
        "            except IndexError:\n",
        "              next\n",
        "          dist_list =[]\n",
        "          dist_list2=[]\n",
        "          hetero_list=[]\n",
        "          hetero_atom=0\n",
        "          for n in range(len(COM_List)):\n",
        "            for n2 in range(len(xyz_list)):\n",
        "              dist = (((float(xyz_list[n2][1])-float(COM_List[n][0]))**2)+((float(xyz_list[n2][2])-float(COM_List[n][1]))**2)+((float(xyz_list[n2][3])-float(COM_List[n][2]))**2))**(1/2)\n",
        "              dist_list.append((dist,n,n2,xyz_list[n2][0]))\n",
        "              if xyz_list[n2][0]!=\"H\" and xyz_list[n2][0]!=\"C\":\n",
        "                dist2 = (((float(xyz_list[n2][1])-float(COM_List[n][0]))**2)+((float(xyz_list[n2][2])-float(COM_List[n][1]))**2)+((float(xyz_list[n2][3])-float(COM_List[n][2]))**2))**(1/2)\n",
        "                hetero_atom=+1\n",
        "                dist_list2.append(dist2)\n",
        "                hetero_list.append(hetero_atom)\n",
        "\n",
        "          total_hetero.append(int(sum(hetero_list)/len(COM_List)))\n",
        "\n",
        "          action_dist1.append(max(dist_list2))\n",
        "          action_dist2.append(max(dist_list)[0])\n",
        "\n",
        "      testfile_name='{}{}.csv'.format(Name,Co)\n",
        "      f2 = open(testfile_name, 'a')\n",
        "\n",
        "      for n in range(len(conf_num)):\n",
        "        try:\n",
        "          print(\"{},{},{},{},{},{}\".format(mass_list[n], action_dist1[n],action_dist2[n],surface_area[n],total_hetero[n], conf_num[n]), file=f2)\n",
        "        except KeyError:\n",
        "          n=+1\n",
        "      f2.close()\n",
        "      file_name2='{}'.format(testfile_name)\n",
        "      google_drive=False\n",
        "\n",
        "      column_names = ['mz', 'COM1', 'COM2', 'SA', 'Hetero_atom','conf#']\n",
        "\n",
        "      raw_dataset2 = pd.read_csv(file_name2,names=column_names,\n",
        "                                na_values='?', comment='\\t',\n",
        "                                index_col= False,\n",
        "                                skipinitialspace=True)\n",
        "\n",
        "\n",
        "      dataset2 = raw_dataset2.copy()\n",
        "\n",
        "      total_dataset= dataset2\n",
        "\n",
        "      try:\n",
        "        test_conf_num = total_dataset.pop('conf#')\n",
        "      except:\n",
        "        KeyError\n",
        "      g=dnn_model.predict(total_dataset)\n",
        "\n",
        "      graph_data = []\n",
        "      conf_ccs_dic={}\n",
        "      for gg in range(len(g)):\n",
        "        conf_ccs_dic[test_conf_num[gg]]=round(float(g[gg]),3)\n",
        "        graph_data.append(conf_ccs_dic[test_conf_num[gg]])\n",
        "      try:\n",
        "        error = abs(test_predictions - test_labels)/test_labels*100\n",
        "        plt.hist(error, bins=100)\n",
        "        plt.xlabel('\\nPrediction %Error [gpCCS]')\n",
        "        _ = plt.ylabel('\\nCount (total test:{})\\n'.format(len(test_predictions)))\n",
        "        sns.displot(error,kind=\"kde\")\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "      dataframe=pd.DataFrame(g, columns=['predicted ccs'])\n",
        "\n",
        "      warnings.filterwarnings('ignore')\n",
        "\n",
        "      conf_ccs_dic={}\n",
        "      for gg in range(len(g)):\n",
        "        conf_ccs_dic[test_conf_num[gg]]=round(float(g[gg]),3)\n",
        "\n",
        "      try:\n",
        "        STD = st.stdev(error)/100\n",
        "      except:\n",
        "        error_load=pd.read_csv(\"error.csv\")\n",
        "        error = error_load[\"gpCCS\"]\n",
        "\n",
        "      STD = st.stdev(error)/100\n",
        "\n",
        "      conf_file = testfile_name.replace(\".csv\",\"\")\n",
        "      focus_file = conf_file\n",
        "      Focus_folder=focus_file.replace(\"_conformer\",\"_focus\")\n",
        "\n",
        "      upper_limit = Experimental_CCS +(Experimental_CCS*STD)\n",
        "      lower_limit = Experimental_CCS -(Experimental_CCS*STD)\n",
        "\n",
        "      if google_drive ==True:\n",
        "        new_DIR=\"{}_CCS_{}\".format(drive_link,Experimental_CCS)\n",
        "        try:\n",
        "          os.mkdir(new_DIR)\n",
        "        except FileExistsError:\n",
        "          print(\"\\n\\nWork file already exist: conformation focusing has already been processed for the entered reference CCS of {}.\".format(Experimental_CCS))\n",
        "          next\n",
        "\n",
        "      if google_drive ==False:\n",
        "        new_DIR=\"{}_CCS_{}\".format(Focus_folder,Experimental_CCS)\n",
        "        drive_link =Focus_folder\n",
        "        try:\n",
        "          os.mkdir(new_DIR)\n",
        "        except FileExistsError:\n",
        "          print(\"\\n\\nWork file already exist: conformation focusing has already been processed for the entered reference CCS of {}.\".format(Experimental_CCS))\n",
        "          next\n",
        "\n",
        "      print(\"\\n\\nUpper limit CCS value: {:.3f}\".format(upper_limit))\n",
        "      print(\"Lower limit CCS value: {:.3f}\".format(lower_limit))\n",
        "\n",
        "      print(\"\\n\\nML Prediction Statistics:\\n----------------------\")\n",
        "      dataframe=pd.DataFrame(g, columns=['CCS Values'])\n",
        "      df = dataframe\n",
        "      print(df.describe(),\"\\n\\n\")\n",
        "\n",
        "\n",
        "      conf_id =(os.listdir(\"{}/\".format(conf_file )))\n",
        "      total=[]\n",
        "      count =0\n",
        "      print(\"\\n\\nCompleted run remark:\\n---------------------\")\n",
        "      for id in conf_id:\n",
        "        try:\n",
        "          id_num=re.sub(\"[^0-9]\", \"\", id)\n",
        "          if lower_limit<= conf_ccs_dic[int(id_num)] <=upper_limit:\n",
        "            count=+1\n",
        "            total.append(count)\n",
        "            shutil.copy(\"{}/{}\".format(conf_file, id), \"{}/{}\".format(new_DIR,id))\n",
        "        except NameError:\n",
        "          next\n",
        "\n",
        "      print(\"Â¶Captured {} conformers out of a total {} conformers\".format(sum(total), len(g)))\n",
        "      print(\"Â¶Captured conformers have been siphoned off to {}\".format(new_DIR))\n",
        "\n",
        "      print(\"\\n\\n\")\n",
        "\n",
        "      if 50 > sum(total) > 0:\n",
        "        up_DIR = new_DIR.split(\"focus\")[0]+\"final\"\n",
        "        shutil.make_archive(new_DIR, 'zip', new_DIR)\n",
        "        files.download(\"{}.zip\".format(new_DIR))\n",
        "      if len(os.listdir(conf_file)) <50:\n",
        "        up2_DIR = conf_file.split(\"_conformer\")[0]+\"_final\"\n",
        "        shutil.make_archive(conf_file, 'zip', conf_file)\n",
        "        files.download(\"{}.zip\".format(conf_file))\n",
        "        print(\"yes\")\n",
        "      if (sum(total)== 0 and len(os.listdir(conf_file))>50) or sum(total)>50:\n",
        "        reduce_list.append(conf_file)\n",
        "\n",
        "\n",
        "\n",
        "      n_bins = 40\n",
        "      fig, axs = plt.subplots(tight_layout=True)\n",
        "      axs.hist(df, bins=n_bins)\n",
        "      plt.title(\"Predicted CCS Distribution\", size=12)\n",
        "      plt.xlabel('\\nCCS (Ã…$^2$)\\n\\n', size='10')\n",
        "      plt.ylabel('\\nOccurrence\\n',  size=\"10\")\n",
        "      plt.plot(Experimental_CCS,1,'*',mec='black',markerfacecolor='r', markersize=11)\n",
        "      plt.legend(labels=['Experiment'])\n",
        "      plt.savefig(\"{}/{}\".format(new_DIR,molecule_name))\n",
        "  except NotADirectoryError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "Ul_OFH_c2jB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normal Walk Conformation Similiarity Reduction**"
      ],
      "metadata": {
        "id": "gvlwYWRR2PXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmsd(coords1, coords2):\n",
        "  coords1 = np.array(coords1)\n",
        "  coords2 = np.array(coords2)\n",
        "  return np.sqrt(np.mean(np.sum((coords1 - coords2)**2, axis=1)))\n",
        "\n",
        "def average_rmsd(conformations):\n",
        "  n_conformations = len(conformations)\n",
        "  total_rmsd = 0\n",
        "  num_pairs = 0\n",
        "  for i in range(n_conformations):\n",
        "    for j in range(i + 1, n_conformations):\n",
        "      total_rmsd += calculate_rmsd(conformations[i], conformations[j])\n",
        "      num_pairs += 1\n",
        "  return total_rmsd / num_pairs\n",
        "\n",
        "def positive_normal(mu, sigma, size=1):\n",
        "    samples = []\n",
        "    while len(samples) < size:\n",
        "        x = np.random.normal(mu, sigma)\n",
        "        if x > 0:\n",
        "            samples.append(x)\n",
        "    return np.array(samples)\n",
        "\n",
        "\n",
        "walk_lib ={}\n",
        "for r in range(len(reduce_list)):\n",
        "  rl = os.listdir(reduce_list[r])\n",
        "  conformations=[]\n",
        "  for cu in range(len(rl)):\n",
        "    try:\n",
        "      B_list = []\n",
        "      if \"xyz\" in rl[cu]:\n",
        "        try:\n",
        "          b = open(reduce_list[r] +\"/\"+ rl[cu])\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "        for B in b:\n",
        "          if len(B.split()) >2:\n",
        "            B_list.append((float(B.split()[1]), float(B.split()[2]), float(B.split()[3])))\n",
        "      conformations.append(np.array(B_list))\n",
        "\n",
        "      stde = np.std(B_list)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  ave_rmsd = average_rmsd(conformations)\n",
        "  walk_steps = 20*num_rotbond\n",
        "  normal_walk = positive_normal(ave_rmsd, stde, size=walk_steps)\n",
        "  walk_lib[reduce_list[r]]= min(normal_walk), (max(normal_walk)-min(normal_walk))/(walk_steps), max(normal_walk)"
      ],
      "metadata": {
        "id": "7gwhx4JCiVoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from openbabel import pybel\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import rdMolDescriptors\n",
        "\n",
        "\n",
        "def calculate_similarity(xyz1, xyz2):\n",
        "    centroid1 = np.mean(xyz1, axis=0)\n",
        "    centroid2 = np.mean(xyz2, axis=0)\n",
        "    xyz1_centered = xyz1 - centroid1\n",
        "    xyz2_centered = xyz2 - centroid2\n",
        "    cov = np.dot(xyz1_centered.T, xyz2_centered)\n",
        "    U, S, V = np.linalg.svd(cov)\n",
        "    rotation_matrix = np.dot(V.T, U.T)\n",
        "    aligned_xyz2 = np.dot(xyz2_centered, rotation_matrix) + centroid1\n",
        "    rmsd = np.sqrt(np.mean(np.sum((aligned_xyz2 - xyz1)**2, axis=1)))\n",
        "    return rmsd\n",
        "\n",
        "def count_rotatable_bonds(smiles):\n",
        "  mole = Chem.MolFromSmiles(smiles)\n",
        "  if mole is None:\n",
        "    raise ValueError(\"Invalid SMILES string\")\n",
        "  return rdMolDescriptors.CalcNumRotatableBonds(mole)\n",
        "\n",
        "def reduce_name(r):\n",
        "  B = r.split(\"/\")[-1]\n",
        "  for b in range(len(B.split(\"_\"))):\n",
        "    if \"Rank\" in B.split(\"_\")[b]:\n",
        "      rank_name = B.split(\"_\")[b]\n",
        "      return rank_name\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for r in range(len(reduce_list)):\n",
        "  rl = os.listdir(reduce_list[r])\n",
        "  step=0\n",
        "  reset_1=1\n",
        "  reset_2=1\n",
        "  max_rmsd = 0\n",
        "  for cu in range(len(rl)):\n",
        "    try:\n",
        "      if \"xyz\" in rl[cu]:\n",
        "        try:\n",
        "          b = open(reduce_list[r] +\"/\"+ rl[cu])\n",
        "        except:\n",
        "          pass\n",
        "        B_list = []\n",
        "\n",
        "        for B in b:\n",
        "          if len(B.split()) >2:\n",
        "            B_list.append((float(B.split()[1]), float(B.split()[2]), float(B.split()[3])))\n",
        "        for cu2 in range(len(rl)):\n",
        "          try:\n",
        "            if rl[cu] != rl[cu2]:\n",
        "              c = open(reduce_list[r]+\"/\"+ rl[cu])\n",
        "              C_list = []\n",
        "              for C in c:\n",
        "                if len(C.split()) >2:\n",
        "                  C_list.append((float(C.split()[1]), float(C.split()[2]), float(C.split()[3])))\n",
        "            try:\n",
        "              molecule1_xyz = np.array(B_list)\n",
        "              molecule2_xyz = np.array(C_list)\n",
        "              similarity_score = calculate_similarity(molecule1_xyz, molecule2_xyz)\n",
        "              num_rot = count_rotatable_bonds(smile)\n",
        "\n",
        "              if float(similarity_score) < (reset_1*walk_lib[reduce_list[r]][0]+step*reset_2)+max_rmsd :\n",
        "                step = walk_lib[reduce_list[r]][1] + step\n",
        "\n",
        "                if step > walk_lib[reduce_list[r]][2]:\n",
        "                  max_rmsd = walk_lib[reduce_list[r]][2]\n",
        "                  reset_1 = 0\n",
        "                  reset_2 = 0\n",
        "                rank_name = reduce_name(reduce_list[r])\n",
        "                link_new =\"/\".join(reduce_list[r].split(\"/\")[:-1])\n",
        "                system_name = (reduce_list[r].split(\"/\")[1])\n",
        "                rxr_dir = link_new +\"/\"+system_name+\"_\" +rank_name +\"_rxr\"\n",
        "                old_dir =reduce_list[r] +\"/\"+ rl[cu]\n",
        "                try:\n",
        "                  os.mkdir(rxr_dir)\n",
        "                except:\n",
        "                  pass\n",
        "                try:\n",
        "                  shutil.move(old_dir, rxr_dir)\n",
        "                  rl = os.listdir(reduce_list[r])\n",
        "                except:\n",
        "                  pass\n",
        "            except:\n",
        "              pass\n",
        "          except:\n",
        "            pass\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "\n",
        "for e in reduce_list:\n",
        "  # if \"_conformer\" in e:\n",
        "\n",
        "  shutil.make_archive(e, 'zip', e)\n",
        "  files.download(\"{}.zip\".format(e))\n",
        "  # else:\n",
        "  #   if \"focus\" in e:\n",
        "  #     final_file = new_DIR.split(\"focus\")[0]+\"final\"\n",
        "  #     shutil.make_archive(final_file, 'zip', final_file)\n",
        "  #     files.download(\"{}.zip\".format(final_file))\n",
        "\n"
      ],
      "metadata": {
        "id": "KZm2g5CZZClp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "try:\n",
        "  shutil.rmtree(user_folder)\n",
        "except:\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "I5wt3ZMrb1jb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}